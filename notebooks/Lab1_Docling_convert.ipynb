{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Hk7eDm0UvuV4"
      },
      "source": [
        "\n",
        "<h1><img src=\"https://simonsanvil.github.io/docling-workshop-pycones-2025/images/DoclingDuck.png\" alt=\"Docling Logo\" style=\"height: 1.5em; vertical-align: middle; margin-right: 0.5em;\" />Transforma tus documentos en datos listos para IA con Docling</h1>\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Lab 1: Conversión de Documentos\n",
        "\n",
        "Bienvenido a el primer lab de esta workshop de Docling. Este viaje de tres partes te llevará desde los conceptos básicos del procesamiento de documentos hasta la construcción de sistemas de IA avanzados y transparentes."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Objetivos\n",
        "\n",
        "En este primer lab, aprenderás a transformar documentos complejos en datos estructurados listos para IA. Pero esto no se trata solo de extracción, sino de una conversión inteligente que preserva todo lo importante para las aplicaciones de IA posteriores.\n",
        "\n",
        "### Al final de este lab, habrás dominado:\n",
        "\n",
        "- **Carga de Documentos**: Ingesta de PDFs, documentos de Word, PowerPoints y más\n",
        "- **Extracción de Estructura**: Preservando de la jerarquía y las relaciones entre los elementos\n",
        "- **Excelencia en Tablas**: Conversión de tablas complejas en formatos utilizables.\n",
        "- **Manejo de Imágenes**: Extracción y preparación de imágenes para el procesamiento de IA.\n",
        "- **Preservación de Metadatos**: Mantenimiento de la información necesaria para referenciar y contextualizar los datos."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "---"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Introducción\n",
        "\n",
        "**[Docling](https://docling-project.github.io/docling/)** es una herramienta de código abierto para el procesamiento, análisis y conversión de documentos diseñado para aplicaciones de IA generativa.\n",
        "\n",
        "### Características Clave\n",
        "- **Soporte multi-formato**: PDF, DOCX, XLSX, HTML, imágenes y más\n",
        "- **Comprensión avanzada de PDF**: Diseño de página, orden de lectura, estructura de tabla, bloques de código, fórmulas\n",
        "- **Representación unificada de DoclingDocument**: Estructura de datos consistente en todos los formatos\n",
        "- **Opciones de exportación flexibles**: Markdown, HTML, JSON, DocTags\n",
        "- **Ejecución local**: Permite procesar datos sensibles sin servicios externos\n",
        "- **Integración con frameworks**: LangChain, LlamaIndex y otros frameworks de IA"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## ¿Por qué usamos Docling para la conversión de documentos?\n",
        "\n",
        "Los datos son la base de todos los sistemas de IA. Para aprovechar la mayor cantidad de datos posible, necesitamos poder ingerir datos de varios formatos con precisión. Sin embargo, los LLM generalmente requieren datos en un formato específico, de ahí la necesidad de conversión.\n",
        "\n",
        "**Sin una conversión adecuada**:\n",
        "- La información se pierde o se desordena\n",
        "- Las tablas se convierten en texto ilegible\n",
        "- Las imágenes desaparecen por completo\n",
        "- La estructura del documento se destruye\n",
        "\n",
        "**Con la conversión avanzada de Docling**:\n",
        "- Cada pieza de información se preserva\n",
        "- Las tablas mantienen su estructura\n",
        "- Las imágenes se extraen y son procesables\n",
        "- El diseño y las relaciones se comprenden"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "LhPuTXE5laO7"
      },
      "source": [
        "### Instalación Básica"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": true,
        "id": "U4UTqpiL8Dfe",
        "outputId": "e111d023-bae6-4548-8fb3-be1958c60107"
      },
      "outputs": [],
      "source": [
        "!uv pip install docling matplotlib pillow pandas python-dotenv"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "TV-71yke857S"
      },
      "source": [
        "### Importamos los componentes esenciales de la librería\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "2eg9Lln_89Cv"
      },
      "outputs": [],
      "source": [
        "from pathlib import Path\n",
        "\n",
        "# Core Docling imports\n",
        "from docling.document_converter import DocumentConverter\n",
        "from docling.datamodel.base_models import InputFormat\n",
        "from docling.datamodel.pipeline_options import PdfPipelineOptions\n",
        "from docling.document_converter import PdfFormatOption\n",
        "\n",
        "# For advanced features\n",
        "from docling_core.types.doc import ImageRefMode, PictureItem, TableItem, TextItem, DoclingDocument\n",
        "\n",
        "# For data processing and visualization\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "# Create output directory\n",
        "output_dir = Path(\"output\")\n",
        "output_dir.mkdir(exist_ok=True)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5N0cmabF_Ria"
      },
      "source": [
        "## 1. Conversión Básica de Documentos\n",
        "\n",
        "### Ejemplo Mínimo\n",
        "\n",
        "La forma más sencilla de convertir un documento es inicializar un `DocumentConverter` y llamar a su método `convert()` con la ruta del fichero o ficheros a convertir.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "PjeZWdaMQq3j"
      },
      "outputs": [],
      "source": [
        "# Docling Technical Report\n",
        "docling_paper = \"https://arxiv.org/pdf/2501.17887\""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "qRBIgujl_01F",
        "outputId": "cc3cb054-fd05-47d2-a5af-d00b48c20b67"
      },
      "outputs": [],
      "source": [
        "# Conversión simple\n",
        "\n",
        "# Crear una instancia del convertidor con parametros por defecto\n",
        "converter = DocumentConverter()\n",
        "\n",
        "# Convertir un documento\n",
        "result = converter.convert(docling_paper)\n",
        "doc = result.document"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "C-OlC5yvlaO7",
        "outputId": "381d699b-bd99-4587-9d6a-616cb3915cb5"
      },
      "outputs": [],
      "source": [
        "# Exportar a Markdown\n",
        "md_out = doc.export_to_markdown()\n",
        "\n",
        "# Imprimir un extracto del resultado\n",
        "print(f\"{md_out[:2000]}...\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "nxDEG2s-lSLq"
      },
      "source": [
        "### Exploración de la Estructura del Documento\n",
        "\n",
        "Uno de las superpoderes de Docling es comprender la estructura del documento, algo crítico a la hora de hacer chunking inteligente o extraer partes específicas del documento."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "VJv614U1lS1x",
        "outputId": "1b7d46bf-0fd3-42c5-c72a-ad316d7e11dc"
      },
      "outputs": [],
      "source": [
        "# Document metadata\n",
        "print(f\"Titulo: {doc.name}\")\n",
        "print(f\"Numero de paginas: {len(doc.pages)}\")\n",
        "print(f\"Numero de tablas: {len(doc.tables)}\")\n",
        "print(f\"Numero de imagenes: {len(doc.pictures)}\")\n",
        "\n",
        "# Exploramos la estructura del documento\n",
        "print(\"\\nEstructura del documento:\")\n",
        "for i, (item, level) in enumerate(doc.iterate_items()):\n",
        "    if i < 10:  # Show first 10 items\n",
        "        item_type = type(item).__name__\n",
        "        text_preview = item.text[:200] if hasattr(item, 'text') else 'N/A'\n",
        "        print(f\"{'  ' * level}{item_type}: {text_preview}\")\n",
        "    else:\n",
        "        break"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "CrrwFDxmHsbz"
      },
      "source": [
        "### Opciones de Exportación\n",
        "\n",
        "Docling ofrece varias opciones de exportación para adaptarse a diferentes necesidades."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "AiCbsd1ifnns"
      },
      "outputs": [],
      "source": [
        "markdown_text = doc.export_to_markdown()  # exportar a markdown (string)\n",
        "html_text = doc.export_to_html() # exportar a html (string)\n",
        "json_dict = doc.export_to_dict() # exportar a dict (json serializable)\n",
        "doc_tags = doc.export_to_doctags() # exportar a doctags (string)\n",
        "\n",
        "# Guardar el documento en varios formatos\n",
        "doc.save_as_markdown(\n",
        "    output_dir / \"document.md\",\n",
        "    image_mode=ImageRefMode.PLACEHOLDER,\n",
        "    image_placeholder=\"<!-- my image placeholder -->\",\n",
        "    # ...\n",
        ")\n",
        "\n",
        "# ...\n",
        "\n",
        "# Exporta a JSON\n",
        "doc.save_as_json(\n",
        "    output_dir / \"document.json\",\n",
        ")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Siéntete libre de explorar los distintos formatos de exportación y visualizar los resultados en comparación con el PDF original."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 2. Inspecciona la salida de DoclingDocument\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6HoHUwTRlwMF"
      },
      "source": [
        "### Tratar con Tablas\n",
        "\n",
        "Docling ofrece excelentes capacidades de extracción de tablas gracias a los modelos [TableFormer](https://github.com/docling-project/docling-ibm-models) que impulsan la extracción de tablas. Para este ejemplo, utilicemos un documento con más tablas."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "kBJvmt1tlaO8"
      },
      "outputs": [],
      "source": [
        "tables_example = \"https://arxiv.org/pdf/2206.01062\""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "5iSBDPf_f4gb",
        "outputId": "6028ed2c-5641-4ea2-894f-8d42bd607b05"
      },
      "outputs": [],
      "source": [
        "# Convertimos el documento\n",
        "table_result = converter.convert(tables_example)\n",
        "table_doc = table_result.document"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "AD7k7Sg_laO8",
        "outputId": "eea71290-ff3f-49af-d427-613e96a45692"
      },
      "outputs": [],
      "source": [
        "print(f\"El documento contiene {len(table_doc.tables)} tablas\")\n",
        "\n",
        "# Exportar todas las tablas\n",
        "for table_idx, table in enumerate(table_doc.tables):\n",
        "    # Convertir a pandas DataFrame\n",
        "    df = table.export_to_dataframe(doc=table_doc)\n",
        "\n",
        "    print(f\"\\n## Tabla {table_idx}\")\n",
        "    print(f\"Dimensiones: {df.shape}\")\n",
        "    display(df.head())\n",
        "\n",
        "    # Save as CSV\n",
        "    df.to_csv(output_dir / f\"table_{table_idx}.csv\", index=False)\n",
        "\n",
        "    # Save as HTML\n",
        "    with open(output_dir / f\"table_{table_idx}.html\", \"w\") as fp:\n",
        "        fp.write(table.export_to_html(doc=table_doc))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8tCfJxhHaIRR"
      },
      "source": [
        "### Extracción de Imágenes\n",
        "\n",
        "Tal como las tablas, Docling también extrae imágenes y las hace accesibles en la estructura del documento."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "EANW0BKX0Q25"
      },
      "source": [
        "#### Extracción y Visualización de Imágenes\n",
        "\n",
        "Podemos configurar la pipeline de Docling para generar imágenes de las páginas del PDF y extraer las imágenes embebidas en el documento. Esto es especialmente útil para documentos con gráficos, diagramas, fotos u otros elementos visuales."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "DNDC06dGaH5M",
        "outputId": "fc27a03f-d8b0-4282-9eb8-b4b4bc014cbb"
      },
      "outputs": [],
      "source": [
        "IMAGE_RESOLUTION_SCALE = 2.0  # 2x resolution (144 DPI)\n",
        "\n",
        "pipeline_options = PdfPipelineOptions(\n",
        "    images_scale=IMAGE_RESOLUTION_SCALE,\n",
        "    generate_page_images=True,\n",
        "    generate_picture_images=True,\n",
        ")\n",
        "\n",
        "converter_with_images = DocumentConverter(\n",
        "    format_options={\n",
        "        InputFormat.PDF: PdfFormatOption(pipeline_options=pipeline_options)\n",
        "    }\n",
        ")\n",
        "\n",
        "# Conversión con extracción de imágenes\n",
        "img_result = converter_with_images.convert(docling_paper) # utilizamos el paper de docling como ejemplo\n",
        "img_doc = img_result.document"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "tVhQ9MSWlaO8",
        "outputId": "24308bf5-7020-48e0-992c-ce01c0102a5a"
      },
      "outputs": [],
      "source": [
        "# Crear directorio para imágenes\n",
        "images_dir = output_dir / \"images\"\n",
        "images_dir.mkdir(exist_ok=True)\n",
        "\n",
        "# Guardar imágenes de las páginas\n",
        "for page_no, page in img_doc.pages.items():\n",
        "    page_image_filename = images_dir / f\"page_{page_no}.png\"\n",
        "    with page_image_filename.open(\"wb\") as fp:\n",
        "        page.image.pil_image.save(fp, format=\"PNG\")\n",
        "\n",
        "print(f\"Saved {len(img_doc.pages)} page images\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Revisa la carpeta `output/` para ver las imágenes extraídas."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "bmfwcH_uUKkp"
      },
      "source": [
        "### Extraer y Guardar Tablas e Imágenes\n",
        "\n",
        "Para un procesamiento personalizado, también podemos extraer figuras y tablas como imágenes:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "kmxxCUVHUKTl",
        "outputId": "e73d0748-eebf-4614-8fcc-e7a84ca25c71"
      },
      "outputs": [],
      "source": [
        "# Extraer y guardar tablas e imágenes\n",
        "table_counter = 0\n",
        "picture_counter = 0\n",
        "\n",
        "for element, level in img_doc.iterate_items():\n",
        "    if isinstance(element, TableItem):\n",
        "        table_counter += 1\n",
        "        image_filename = images_dir / f\"table_{table_counter}.png\"\n",
        "        with image_filename.open(\"wb\") as fp:\n",
        "            element.get_image(img_doc).save(fp, \"PNG\")\n",
        "\n",
        "    elif isinstance(element, PictureItem):\n",
        "        picture_counter += 1\n",
        "        image_filename = images_dir / f\"figure_{picture_counter}.png\"\n",
        "        with image_filename.open(\"wb\") as fp:\n",
        "            element.get_image(img_doc).save(fp, \"PNG\")\n",
        "\n",
        "print(f\"Extraído {table_counter} tabla(s) y {picture_counter} figuras como imágenes\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8pxfi8azdLTQ"
      },
      "source": [
        "### Inspeccionar el Contenido de las Imágenes\n",
        "\n",
        "Docling preservará automáticamente los subtítulos y extraerá el contenido de texto de las imágenes extraídas. Veamos qué se ha extraído:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Ia--zHY9dNQc",
        "outputId": "4c950171-48e4-43e8-f283-0d84c9a206b7"
      },
      "outputs": [],
      "source": [
        "def inspect_pictures_with_images(doc: DoclingDocument, image_size=(6, 4)):\n",
        "    \"\"\"Display pictures inline with their text content\"\"\"\n",
        "    for idx, picture in enumerate(doc.pictures):\n",
        "        print(f\"\\n{'='*60}\")\n",
        "        print(f\"Imagen {idx}\")\n",
        "        print(f\"{'='*60}\")\n",
        "\n",
        "        # Display the image\n",
        "        try:\n",
        "            img = picture.get_image(doc)\n",
        "            if img:\n",
        "                plt.figure(figsize=image_size)\n",
        "                plt.imshow(img)\n",
        "                plt.axis('off')\n",
        "                plt.title(f\"Picture {idx}\")\n",
        "                plt.show()\n",
        "        except Exception as e:\n",
        "            print(f\"Could not display image: {e}\")\n",
        "\n",
        "        # Display metadata\n",
        "        caption = picture.caption_text(doc)\n",
        "        if caption:\n",
        "            print(f\"Subtitulo: {caption}\")\n",
        "\n",
        "        if hasattr(picture, 'prov') and picture.prov:\n",
        "            print(f\"Location: Page {picture.prov[0].page_no}\")\n",
        "\n",
        "        # Display embedded text\n",
        "        print(\"\\nTexto embebido:\")\n",
        "        text_found = False\n",
        "        for item, level in doc.iterate_items(root=picture, traverse_pictures=True):\n",
        "            if isinstance(item, TextItem):\n",
        "                print(f\"{'  ' * (level + 1)}- {item.text}\")\n",
        "                text_found = True\n",
        "\n",
        "        if not text_found:\n",
        "            print(\"  (No text elements found)\")\n",
        "\n",
        "# Use the simple inline display\n",
        "inspect_pictures_with_images(img_doc)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8hjtRz-mq1Id"
      },
      "source": [
        "### Visualización de la Estructura del Documento con Bounding Boxes\n",
        "\n",
        "Para entender cómo se extrae cada parte del documento, visualicemos los elementos extraídos. Podemos hacer esto utilizando uno de los visualizadores integrados en Docling:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "dt_xLM4blaO8",
        "outputId": "ff8d949d-5264-4002-cff3-9b3d6ab5821a"
      },
      "outputs": [],
      "source": [
        "from docling_core.transforms.visualizer.layout_visualizer import LayoutVisualizer\n",
        "\n",
        "layout_visualizer = LayoutVisualizer()\n",
        "page_images = layout_visualizer.get_visualization(doc=img_doc)\n",
        "\n",
        "num_pages_to_viz = 2  # first N pages to visualize\n",
        "pages_to_viz = list(page_images.keys())[:num_pages_to_viz]\n",
        "for page in pages_to_viz:\n",
        "    display(page_images[page])"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "LkBT1FFUwzYN"
      },
      "source": [
        "## 3. Enriquecimiento de Imagenes con VLM"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "yDM-OeUgy0ym"
      },
      "source": [
        "### Clasificación y Descripción de Imágenes\n",
        "\n",
        "Además de las capacidades básicas de subtitulado, Docling también puede procesar imágenes utilizando LLMs multimodales. Esto nos dará descripciones de imágenes más detalladas para ayudarnos a aprovechar los datos de las imágenes de manera más efectiva.\n",
        "\n",
        "Existen dos formas de hacer esto en Docling:\n",
        "\n",
        "1. Con modelos de HuggingFace cargados localmente: Este método es gratuito pero generalmente requiere hardware potente o utilizar modelos pequeños como [SmolVLM](https://huggingface.co/HuggingFaceTB/SmolVLM-500M-Instruct) que pueden no ser tan precisos.\n",
        "2. Utilizando un VLLM basado en API: Si estas sirviendo un modelo de visión a través de una API como Ollama, [watsonx.ai](https://watsonx.ai/), o cualquiera que sea compatible con la API de OpenAI, puedes usarla para procesar las imágenes. Este método es generalmente más preciso y fácil de usar, pero puede incurrir en costos dependiendo del proveedor y el uso."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "RUN_LOCAL_VLM = True"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "referenced_widgets": [
            "4ba3a486c40d4b39ae7c4bb6c004b440"
          ]
        },
        "id": "WXMHPBTdDkev",
        "outputId": "5c21974b-e704-44bb-b0c8-6a6cedfdaaab"
      },
      "outputs": [],
      "source": [
        "from docling.datamodel.pipeline_options import PictureDescriptionApiOptions, PictureDescriptionVlmOptions\n",
        "\n",
        "# Configure enrichment pipeline\n",
        "if RUN_LOCAL_VLM:\n",
        "    # activamos enriquecimiento de imagenes con un modelo VLM local\n",
        "    # (NOTA: si tu runtime no tiene GPUs, el rendimiento puede llegar a ser muy lento)\n",
        "    VLM_REPO_NAME = \"HuggingFaceTB/SmolVLM-500M-Instruct\"\n",
        "    VLM_MODEL_NAME = VLM_REPO_NAME.split(\"/\")[-1]\n",
        "    enrichment_options = PdfPipelineOptions(\n",
        "        do_picture_description=True,\n",
        "        picture_description_options=PictureDescriptionVlmOptions(\n",
        "            repo_id=VLM_REPO_NAME,\n",
        "            prompt=\"Describe in detail what is depicted in the image\",\n",
        "            generation_config=dict(\n",
        "                max_new_tokens=400,\n",
        "                do_sample=False\n",
        "            )\n",
        "        ),\n",
        "        generate_picture_images=True, # preserva las imagenes de las figuras para poder exportarlas luego\n",
        "        images_scale=1.0,\n",
        "    )\n",
        "else:\n",
        "    # activamos enriquecimiento de imagenes con un modelo VLM remoto (requiere endpoint compatible con OpenAI)\n",
        "    VLM_MODEL_NAME = \"granite-vision-3.3-2b\"\n",
        "    enrichment_options = PdfPipelineOptions(\n",
        "        do_picture_description=True,\n",
        "        enable_remote_services=True,\n",
        "        picture_description_options=PictureDescriptionApiOptions(\n",
        "            # cualquier endpoint de LLMs compatible con la API de OpenAI funcionaría (e.g., ollama, litellm, LMStudio, ...)\n",
        "            url=\"http://0.0.0.0:4000/v1/chat/completions\",  \n",
        "            params=dict(\n",
        "                model=VLM_MODEL_NAME,\n",
        "                seed=42,\n",
        "                max_tokens=400,\n",
        "                provenance=VLM_MODEL_NAME,\n",
        "            ),\n",
        "            prompt=\"Give a detailed description of what is depicted in the image\",\n",
        "            concurrency=4, \n",
        "            picture_area_threshold=0.1,\n",
        "            timeout=90,\n",
        "        ),\n",
        "        generate_picture_images=True, # preserva las imagenes de las figuras para poder exportarlas luego\n",
        "        images_scale=1.0,\n",
        "    )\n",
        "\n",
        "\n",
        "converter_enriched = DocumentConverter(\n",
        "    format_options={\n",
        "        InputFormat.PDF: PdfFormatOption(pipeline_options=enrichment_options)\n",
        "    }\n",
        ")\n",
        "enr_result = converter_enriched.convert(docling_paper)\n",
        "enr_doc = enr_result.document"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "vUVWwmcq4SJE",
        "outputId": "374020e2-a78e-488f-a74f-b1c3eb288541"
      },
      "outputs": [],
      "source": [
        "from docling_core.types.doc.document import PictureDescriptionData\n",
        "from IPython import display\n",
        "\n",
        "html_buffer = []\n",
        "# display the first 5 pictures and their captions and annotations:\n",
        "for pic in enr_doc.pictures[:5]:\n",
        "    html_item = (\n",
        "        f\"<h3>Picture <code>{pic.self_ref}</code></h3>\"\n",
        "        f'<img src=\"{pic.image.uri!s}\" /><br />'\n",
        "        f\"<h4>Caption</h4>{pic.caption_text(doc=doc)}<br />\"\n",
        "    )\n",
        "    for annotation in pic.annotations:\n",
        "        if not isinstance(annotation, PictureDescriptionData):\n",
        "            continue\n",
        "        html_item += (\n",
        "            f\"<h4>Annotations ({VLM_MODEL_NAME})</h4>{annotation.text}<br />\\n\"\n",
        "        )\n",
        "    html_buffer.append(html_item)\n",
        "display.HTML(\"<hr />\".join(html_buffer))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "UStdCE9f1RgJ"
      },
      "source": [
        "## Resumen\n",
        "\n",
        "### Lo que has logrado en el Laboratorio 1\n",
        "\n",
        "¡Felicidades! Has dominado el primer paso crítico en la IA de documentos:\n",
        "\n",
        "- Conversión de documentos básica y avanzada con retroalimentación visual\n",
        "- Múltiples formatos de exportación con opciones de visualización\n",
        "- Extracción de tablas e imágenes con verificación visual\n",
        "- Modelos de enriquecimiento y VLMs\n",
        "\n",
        "### Próximos Pasos\n",
        "\n",
        "Puedes continuar explorando Docling por tu cuenta probando con tus propios documentos o documentos más complejos, o avanzar al siguiente laboratorio en esta serie.\n",
        "\n",
        "Para más información, explora los recursos a continuación:\n",
        "\n",
        "- GitHub: https://github.com/docling-project/docling\n",
        "- Documentation: https://docling-project.github.io/docling/\n",
        "- Technical Report: https://arxiv.org/abs/2408.09869\n",
        "- Examples: https://github.com/docling-project/docling/tree/main/examples"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": []
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "gpuType": "T4",
      "provenance": []
    },
    "kernelspec": {
      "display_name": ".venv",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.12.5"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
